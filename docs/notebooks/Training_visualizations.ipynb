{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Visdom\n",
    "\n",
    "Install it with:\n",
    "\n",
    "`pip install visdom`\n",
    "\n",
    "Start the server:\n",
    "\n",
    "`python -m visdom.server`\n",
    "\n",
    "Visdom now can be accessed at http://localhost:8097 in the browser.\n",
    "\n",
    "\n",
    "# LDA Training Visualization\n",
    "\n",
    "To monitor the LDA training, a list of Metrics can be passed to the LDA function call for plotting their values live as the training progresses.  \n",
    "\n",
    "Let's plot the training stats for an LDA model being trained on Lee corpus. We will use the four evaluation metrics available for topic models in gensim: Coherence, Perplexity, Topic diff and Convergence. (using separate hold_out and test corpus for evaluating the perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import gensim\n",
    "from gensim.models import ldamodel\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "\n",
    "# Set file names for train and test data\n",
    "test_data_dir = '{}'.format(os.sep).join([gensim.__path__[0], 'test', 'test_data'])\n",
    "lee_train_file = test_data_dir + os.sep + 'lee_background.cor'\n",
    "lee_test_file = test_data_dir + os.sep + 'lee.cor'\n",
    "\n",
    "def read_corpus(fname):\n",
    "    texts = []\n",
    "    with open(fname, encoding=\"ISO-8859-1\") as f:\n",
    "        for line in f:\n",
    "            # lower case all words\n",
    "            lowered = line.lower()\n",
    "            # remove punctuation and split into seperate words\n",
    "            words = re.compile('\\w+').findall(lowered)\n",
    "            texts.append(words)\n",
    "    return texts\n",
    "\n",
    "training_texts = read_corpus(lee_train_file)\n",
    "test_texts = read_corpus(lee_test_file)\n",
    "\n",
    "# Split test data into hold_out and test corpus\n",
    "holdout_texts = test_texts[:150]\n",
    "test_texts = test_texts[150:]\n",
    "\n",
    "dictionary = Dictionary(training_texts)\n",
    "\n",
    "training_corpus = [dictionary.doc2bow(text) for text in training_texts]\n",
    "holdout_corpus = [dictionary.doc2bow(text) for text in holdout_texts]\n",
    "test_corpus = [dictionary.doc2bow(text) for text in test_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models.callbacks import CoherenceMetric, DiffMetric, PerplexityMetric, ConvergenceMetric\n",
    "\n",
    "# define perplexity callback for hold_out and test corpus\n",
    "pl_holdout = PerplexityMetric(corpus=holdout_corpus, logger=\"visdom\", viz_env=\"LdaModel\", title=\"Perplexity\")\n",
    "pl_test = PerplexityMetric(corpus=test_corpus, logger=\"visdom\", viz_env=\"LdaModel\", title=\"Perplexity\")\n",
    "\n",
    "# define other remaining metrics available\n",
    "ch_umass = CoherenceMetric(corpus=training_corpus, coherence=\"u_mass\", logger=\"visdom\", viz_env=\"LdaModel\", title=\"Coherence (u_mass)\")\n",
    "diff_kl = DiffMetric(distance=\"kullback_leibler\", logger=\"visdom\", viz_env=\"LdaModel\", title=\"Diff (kullback_leibler)\")\n",
    "convergence_jc = ConvergenceMetric(distance=\"jaccard\", logger=\"visdom\", viz_env=\"LdaModel\", title=\"Convergence (jaccard)\")\n",
    "\n",
    "callbacks = [pl_holdout, pl_test, ch_umass, diff_kl, convergence_jc]\n",
    "\n",
    "# training LDA model\n",
    "model = ldamodel.LdaModel(corpus=training_corpus, id2word=dictionary, passes=5, num_topics=5, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the model is set for training, you can open http://localhost:8097 to see the training progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# to get a metric value on a trained model\n",
    "print(CoherenceMetric(corpus=training_corpus, coherence=\"u_mass\").get_value(model=model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The four types of graphs which are plotted for LDA:\n",
    "\n",
    "**Coherence**\n",
    "\n",
    "Coherence is a measure used to evaluate topic models. A good model will generate coherent topics, i.e., topics         with high topic coherence scores. Good topics are topics that can be described by a short label based on the topic     terms they spit out. \n",
    "\n",
    "<img src=\"Coherence.gif\">\n",
    "\n",
    "Now, this graph along with the others explained below, can be used to decide if it's time to stop the training. We     can see if the value stops changing after some epochs and that we are able to get the highest possible coherence       of our model.  \n",
    "\n",
    "\n",
    "**Perplexity**\n",
    "\n",
    "Perplexity is a measurement of how well a probability distribution or probability model predicts a sample. In LDA, topics are described by a probability distribution over vocabulary words. So, perplexity can be used to compare probabilistic models like LDA.\n",
    "\n",
    "<img src=\"Perplexity.gif\">\n",
    "\n",
    "For a good model, perplexity should be as low as possible.\n",
    "\n",
    "\n",
    "**Topic Difference**\n",
    "\n",
    "Topic Diff calculates the distance between two LDA models. This distance is calculated based on the topics, by either using their probability distribution over vocabulary words (kullback_leibler, hellinger) or by simply using the common vocabulary words between the topics from both model.\n",
    "\n",
    "<img src=\"Diff.gif\">\n",
    "\n",
    "In the heatmap, X-axis define the Epoch no. and Y-axis define the distance between the identical topic from consecutive epochs. For ex. a particular cell in the heatmap with values (x=3, y=5, z=0.4) represent the distance(=0.4) between the topic 5 from 3rd epoch and topic 5 from 2nd epoch. With increasing epochs, the distance between the identical topics should decrease.\n",
    "  \n",
    "  \n",
    "**Convergence**\n",
    "\n",
    "Convergence is the sum of the difference between all the identical topics from two consecutive epochs. It is basically the sum of column values in the heatmap above.\n",
    "\n",
    "<img src=\"Convergence.gif\">\n",
    "\n",
    "The model is said to be converged when the convergence value stops descending with increasing epochs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
